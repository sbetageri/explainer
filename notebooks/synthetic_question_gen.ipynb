{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:19.104656Z",
     "start_time": "2025-12-29T17:33:19.101867Z"
    }
   },
   "cell_type": "code",
   "source": "import time",
   "id": "21c7700b2492c78c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:19.314882Z",
     "start_time": "2025-12-29T17:33:19.312301Z"
    }
   },
   "cell_type": "code",
   "source": "import json",
   "id": "f91d75ef6b769e95",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:19.485946Z",
     "start_time": "2025-12-29T17:33:19.484311Z"
    }
   },
   "source": "import anthropic",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:19.651734Z",
     "start_time": "2025-12-29T17:33:19.650083Z"
    }
   },
   "cell_type": "code",
   "source": "import random",
   "id": "ac378bd6274dcceb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:19.848544Z",
     "start_time": "2025-12-29T17:33:19.846164Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm import tqdm",
   "id": "7e1317e627ccf9ce",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:20.018670Z",
     "start_time": "2025-12-29T17:33:20.016424Z"
    }
   },
   "cell_type": "code",
   "source": "from pathlib import Path",
   "id": "4c159dfd61cc5c4b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:20.203941Z",
     "start_time": "2025-12-29T17:33:20.202081Z"
    }
   },
   "cell_type": "code",
   "source": "from pydantic import BaseModel, Field",
   "id": "ae7efcb3c699e334",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:20.352736Z",
     "start_time": "2025-12-29T17:33:20.350387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SONNET = 'claude-sonnet-4-5'\n",
    "HAIKU = 'claude-haiku-4-5'"
   ],
   "id": "1a4206629923317d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:20.574426Z",
     "start_time": "2025-12-29T17:33:20.549629Z"
    }
   },
   "cell_type": "code",
   "source": "CLIENT = anthropic.Anthropic()",
   "id": "6a6873f9b2919e94",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:20.743865Z",
     "start_time": "2025-12-29T17:33:20.741809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROLE = 'role'\n",
    "CONTENT = 'content'\n",
    "SYSTEM = 'system'\n",
    "USER = 'user'\n",
    "ASSISTANT = 'assistant'"
   ],
   "id": "553eb7f7ae203850",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:20.931023Z",
     "start_time": "2025-12-29T17:33:20.928934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_TOKENS = 'input_tokens'\n",
    "TOKEN_LIMIT = 10_000"
   ],
   "id": "f675b7d88b57f15a",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:21.127174Z",
     "start_time": "2025-12-29T17:33:21.124826Z"
    }
   },
   "cell_type": "code",
   "source": "FILES = 'files'",
   "id": "d8f2e13f78bf90d0",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:21.303875Z",
     "start_time": "2025-12-29T17:33:21.301734Z"
    }
   },
   "cell_type": "code",
   "source": "FILE_NAME = 'file_name'",
   "id": "cd3114d9f750f559",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:44:10.862698Z",
     "start_time": "2025-12-29T17:44:10.860007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYS_PROMPT = \"\"\"\n",
    "You are helping to generate a dataset for RAG evaluation, using only the given documents.\n",
    "\"\"\"\n",
    "QS_PROMPT = \"\"\"\n",
    "You will be given access to information pertaining to a software package.\n",
    "\n",
    "You are to generate a question only based on the given document.\n",
    "Each question should be fully answerable using only that one document.\n",
    "The question should be something that a staff software engineer would want to ask from the documentation.\n",
    "The question can be sligthly vague, but not too vague.\n",
    "Avoid lifting technical words and snippets from the document directly.\n",
    "The question should be something that a staff software engineer would ask, and the answer must be from the documentation.\n",
    "\n",
    "document : {document}\n",
    "\"\"\""
   ],
   "id": "6ef8b9639d2229e5",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:47:32.648196Z",
     "start_time": "2025-12-29T17:47:32.646023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "QS = 'question'\n",
    "REASON = 'reasoning'\n",
    "FILE_PATH = 'file_path'"
   ],
   "id": "765b19fb18f141d4",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:52:16.244266Z",
     "start_time": "2025-12-29T17:52:16.242594Z"
    }
   },
   "cell_type": "code",
   "source": "EVAL_QS = 'eval_questions'",
   "id": "8f5b198ad4966495",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:34:33.357902Z",
     "start_time": "2025-12-29T17:34:33.356177Z"
    }
   },
   "cell_type": "code",
   "source": "BETAS_STRUCTURED_OUTPUT = 'structured-outputs-2025-11-13'",
   "id": "ca3d4adbe2ae2b55",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:21.712493Z",
     "start_time": "2025-12-29T17:33:21.709757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuestionGen(BaseModel):\n",
    "    reasoning: str = Field(description=\"Thought process and reasoning behind the question\")\n",
    "    question: str = Field(description=\"Question\")"
   ],
   "id": "4b8e5db64cbe81a0",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:21.926596Z",
     "start_time": "2025-12-29T17:33:21.924265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_all_files_in_dir(root_dir: str, file_ext:str = '.md') -> list:\n",
    "    \"\"\"Get a list of all files in root_dir\"\"\"\n",
    "    root_dir = Path(root_dir)\n",
    "    file_paths = list(root_dir.glob('*' + file_ext))\n",
    "    return file_paths"
   ],
   "id": "5673470ddf795475",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:22.331970Z",
     "start_time": "2025-12-29T17:33:22.328958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def choose_random_files(file_paths: list, k=200) -> list:\n",
    "    \"\"\"Choose k random files\"\"\"\n",
    "    chosen_splits = set()\n",
    "    while len(chosen_splits) < k:\n",
    "        file_path = random.choice(file_paths)\n",
    "        file_md = read_file(file_path)\n",
    "        num_tokens = get_num_tokens(file_md)\n",
    "        time.sleep(1)\n",
    "        if num_tokens <= TOKEN_LIMIT:\n",
    "            chosen_splits.add(file_path)\n",
    "            print(f'Added file to sample. Num Files : {len(chosen_splits)}')\n",
    "    return list(chosen_splits)"
   ],
   "id": "cd42620ec4cf717f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:22.758939Z",
     "start_time": "2025-12-29T17:33:22.755726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_num_tokens(input_str: str) -> int:\n",
    "    \"\"\"Get number of tokens in input_str\"\"\"\n",
    "    response = CLIENT.messages.count_tokens(\n",
    "        model=SONNET,\n",
    "        system='You are a helpful assistant',\n",
    "        messages=[{\n",
    "            ROLE: USER,\n",
    "            CONTENT: input_str\n",
    "        }],\n",
    "    )\n",
    "    response = json.loads(response.model_dump_json())\n",
    "    tokens = response[INPUT_TOKENS]\n",
    "    return tokens"
   ],
   "id": "3ade8f0a2b3fb755",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:23.138516Z",
     "start_time": "2025-12-29T17:33:23.135554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_file(file_path: str) -> str:\n",
    "    \"\"\"Read a file\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()"
   ],
   "id": "a16029fc7bc652dd",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:23.674343Z",
     "start_time": "2025-12-29T17:33:23.671222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_eval_samples(sample_path: str) -> list:\n",
    "    \"\"\"Load the samples for eval\"\"\"\n",
    "    with open(sample_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ],
   "id": "283dd90385965a02",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:39:59.193223Z",
     "start_time": "2025-12-29T17:39:59.190904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_question(content_str: str, prompt=QS_PROMPT, model=SONNET):\n",
    "    \"\"\"Generate a question\"\"\"\n",
    "    response = CLIENT.beta.messages.parse(\n",
    "        model=model,\n",
    "        betas=[BETAS_STRUCTURED_OUTPUT],\n",
    "        max_tokens=1024,\n",
    "        output_format=QuestionGen,\n",
    "        system=SYS_PROMPT,\n",
    "        messages=[\n",
    "            {\n",
    "                ROLE: USER,\n",
    "                CONTENT: prompt.format(document=content_str),\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.parsed_output"
   ],
   "id": "5e693400509432be",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:48:26.234300Z",
     "start_time": "2025-12-29T17:48:26.231200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gen_qs_detail(question_obj: QuestionGen, file_path: str):\n",
    "    \"\"\"Generate a question detail\"\"\"\n",
    "    return {\n",
    "        QS: question_obj.question,\n",
    "        REASON: question_obj.reasoning,\n",
    "        FILE_PATH: file_path,\n",
    "    }"
   ],
   "id": "78e2aa2c3838a709",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:54:40.556415Z",
     "start_time": "2025-12-29T17:54:40.552290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_questions(file_paths, prompt=QS_PROMPT, model=SONNET, save_path:str='../working_dir/eval/eval_questions.json'):\n",
    "    \"\"\"Generate questions for all the files\"\"\"\n",
    "    results = []\n",
    "    for file_path in tqdm(file_paths[FILES]):\n",
    "        file_md = read_file(file_path)\n",
    "        question = generate_question(content_str=file_md, prompt=prompt, model=model)\n",
    "        qs_detail = gen_qs_detail(question, file_path)\n",
    "        results.append(qs_detail)\n",
    "        with open(save_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                EVAL_QS: results\n",
    "            }, f)\n",
    "    return results"
   ],
   "id": "14e0314adc08cb18",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:54:41.093509Z",
     "start_time": "2025-12-29T17:54:41.089156Z"
    }
   },
   "cell_type": "code",
   "source": "data = load_eval_samples('../working_dir/eval/sample.json')",
   "id": "c33719912316353a",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T18:16:40.105592Z",
     "start_time": "2025-12-29T17:54:41.750581Z"
    }
   },
   "cell_type": "code",
   "source": "results = generate_questions(data)",
   "id": "825b0028dbfe298b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questions for 1/200\n",
      "Generating questions for 2/200\n",
      "Generating questions for 3/200\n",
      "Generating questions for 4/200\n",
      "Generating questions for 5/200\n",
      "Generating questions for 6/200\n",
      "Generating questions for 7/200\n",
      "Generating questions for 8/200\n",
      "Generating questions for 9/200\n",
      "Generating questions for 10/200\n",
      "Generating questions for 11/200\n",
      "Generating questions for 12/200\n",
      "Generating questions for 13/200\n",
      "Generating questions for 14/200\n",
      "Generating questions for 15/200\n",
      "Generating questions for 16/200\n",
      "Generating questions for 17/200\n",
      "Generating questions for 18/200\n",
      "Generating questions for 19/200\n",
      "Generating questions for 20/200\n",
      "Generating questions for 21/200\n",
      "Generating questions for 22/200\n",
      "Generating questions for 23/200\n",
      "Generating questions for 24/200\n",
      "Generating questions for 25/200\n",
      "Generating questions for 26/200\n",
      "Generating questions for 27/200\n",
      "Generating questions for 28/200\n",
      "Generating questions for 29/200\n",
      "Generating questions for 30/200\n",
      "Generating questions for 31/200\n",
      "Generating questions for 32/200\n",
      "Generating questions for 33/200\n",
      "Generating questions for 34/200\n",
      "Generating questions for 35/200\n",
      "Generating questions for 36/200\n",
      "Generating questions for 37/200\n",
      "Generating questions for 38/200\n",
      "Generating questions for 39/200\n",
      "Generating questions for 40/200\n",
      "Generating questions for 41/200\n",
      "Generating questions for 42/200\n",
      "Generating questions for 43/200\n",
      "Generating questions for 44/200\n",
      "Generating questions for 45/200\n",
      "Generating questions for 46/200\n",
      "Generating questions for 47/200\n",
      "Generating questions for 48/200\n",
      "Generating questions for 49/200\n",
      "Generating questions for 50/200\n",
      "Generating questions for 51/200\n",
      "Generating questions for 52/200\n",
      "Generating questions for 53/200\n",
      "Generating questions for 54/200\n",
      "Generating questions for 55/200\n",
      "Generating questions for 56/200\n",
      "Generating questions for 57/200\n",
      "Generating questions for 58/200\n",
      "Generating questions for 59/200\n",
      "Generating questions for 60/200\n",
      "Generating questions for 61/200\n",
      "Generating questions for 62/200\n",
      "Generating questions for 63/200\n",
      "Generating questions for 64/200\n",
      "Generating questions for 65/200\n",
      "Generating questions for 66/200\n",
      "Generating questions for 67/200\n",
      "Generating questions for 68/200\n",
      "Generating questions for 69/200\n",
      "Generating questions for 70/200\n",
      "Generating questions for 71/200\n",
      "Generating questions for 72/200\n",
      "Generating questions for 73/200\n",
      "Generating questions for 74/200\n",
      "Generating questions for 75/200\n",
      "Generating questions for 76/200\n",
      "Generating questions for 77/200\n",
      "Generating questions for 78/200\n",
      "Generating questions for 79/200\n",
      "Generating questions for 80/200\n",
      "Generating questions for 81/200\n",
      "Generating questions for 82/200\n",
      "Generating questions for 83/200\n",
      "Generating questions for 84/200\n",
      "Generating questions for 85/200\n",
      "Generating questions for 86/200\n",
      "Generating questions for 87/200\n",
      "Generating questions for 88/200\n",
      "Generating questions for 89/200\n",
      "Generating questions for 90/200\n",
      "Generating questions for 91/200\n",
      "Generating questions for 92/200\n",
      "Generating questions for 93/200\n",
      "Generating questions for 94/200\n",
      "Generating questions for 95/200\n",
      "Generating questions for 96/200\n",
      "Generating questions for 97/200\n",
      "Generating questions for 98/200\n",
      "Generating questions for 99/200\n",
      "Generating questions for 100/200\n",
      "Generating questions for 101/200\n",
      "Generating questions for 102/200\n",
      "Generating questions for 103/200\n",
      "Generating questions for 104/200\n",
      "Generating questions for 105/200\n",
      "Generating questions for 106/200\n",
      "Generating questions for 107/200\n",
      "Generating questions for 108/200\n",
      "Generating questions for 109/200\n",
      "Generating questions for 110/200\n",
      "Generating questions for 111/200\n",
      "Generating questions for 112/200\n",
      "Generating questions for 113/200\n",
      "Generating questions for 114/200\n",
      "Generating questions for 115/200\n",
      "Generating questions for 116/200\n",
      "Generating questions for 117/200\n",
      "Generating questions for 118/200\n",
      "Generating questions for 119/200\n",
      "Generating questions for 120/200\n",
      "Generating questions for 121/200\n",
      "Generating questions for 122/200\n",
      "Generating questions for 123/200\n",
      "Generating questions for 124/200\n",
      "Generating questions for 125/200\n",
      "Generating questions for 126/200\n",
      "Generating questions for 127/200\n",
      "Generating questions for 128/200\n",
      "Generating questions for 129/200\n",
      "Generating questions for 130/200\n",
      "Generating questions for 131/200\n",
      "Generating questions for 132/200\n",
      "Generating questions for 133/200\n",
      "Generating questions for 134/200\n",
      "Generating questions for 135/200\n",
      "Generating questions for 136/200\n",
      "Generating questions for 137/200\n",
      "Generating questions for 138/200\n",
      "Generating questions for 139/200\n",
      "Generating questions for 140/200\n",
      "Generating questions for 141/200\n",
      "Generating questions for 142/200\n",
      "Generating questions for 143/200\n",
      "Generating questions for 144/200\n",
      "Generating questions for 145/200\n",
      "Generating questions for 146/200\n",
      "Generating questions for 147/200\n",
      "Generating questions for 148/200\n",
      "Generating questions for 149/200\n",
      "Generating questions for 150/200\n",
      "Generating questions for 151/200\n",
      "Generating questions for 152/200\n",
      "Generating questions for 153/200\n",
      "Generating questions for 154/200\n",
      "Generating questions for 155/200\n",
      "Generating questions for 156/200\n",
      "Generating questions for 157/200\n",
      "Generating questions for 158/200\n",
      "Generating questions for 159/200\n",
      "Generating questions for 160/200\n",
      "Generating questions for 161/200\n",
      "Generating questions for 162/200\n",
      "Generating questions for 163/200\n",
      "Generating questions for 164/200\n",
      "Generating questions for 165/200\n",
      "Generating questions for 166/200\n",
      "Generating questions for 167/200\n",
      "Generating questions for 168/200\n",
      "Generating questions for 169/200\n",
      "Generating questions for 170/200\n",
      "Generating questions for 171/200\n",
      "Generating questions for 172/200\n",
      "Generating questions for 173/200\n",
      "Generating questions for 174/200\n",
      "Generating questions for 175/200\n",
      "Generating questions for 176/200\n",
      "Generating questions for 177/200\n",
      "Generating questions for 178/200\n",
      "Generating questions for 179/200\n",
      "Generating questions for 180/200\n",
      "Generating questions for 181/200\n",
      "Generating questions for 182/200\n",
      "Generating questions for 183/200\n",
      "Generating questions for 184/200\n",
      "Generating questions for 185/200\n",
      "Generating questions for 186/200\n",
      "Generating questions for 187/200\n",
      "Generating questions for 188/200\n",
      "Generating questions for 189/200\n",
      "Generating questions for 190/200\n",
      "Generating questions for 191/200\n",
      "Generating questions for 192/200\n",
      "Generating questions for 193/200\n",
      "Generating questions for 194/200\n",
      "Generating questions for 195/200\n",
      "Generating questions for 196/200\n",
      "Generating questions for 197/200\n",
      "Generating questions for 198/200\n",
      "Generating questions for 199/200\n",
      "Generating questions for 200/200\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T18:17:16.066439Z",
     "start_time": "2025-12-29T18:17:16.047506Z"
    }
   },
   "cell_type": "markdown",
   "source": "#k Scratch Code",
   "id": "28e393b2a67fd9bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:26.870027Z",
     "start_time": "2025-12-29T17:33:26.866636Z"
    }
   },
   "cell_type": "code",
   "source": "data = load_eval_samples('../working_dir/eval/sample.json')",
   "id": "5e7a519b02fd4f98",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:33:27.731182Z",
     "start_time": "2025-12-29T17:33:27.725712Z"
    }
   },
   "cell_type": "code",
   "source": "len(data[FILES])",
   "id": "c81dea08464e9be4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:44:20.674182Z",
     "start_time": "2025-12-29T17:44:12.932016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx = 0\n",
    "md_str = read_file(data[FILES][idx])\n",
    "question = generate_question(md_str)"
   ],
   "id": "672765db1e86973e",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:44:20.689041Z",
     "start_time": "2025-12-29T17:44:20.685669Z"
    }
   },
   "cell_type": "code",
   "source": "question.reasoning",
   "id": "69709389602ae092",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This document is about the FaithfulnessEvaluator, which is part of an evaluation SDK for testing agent responses. A staff software engineer would likely want to understand the practical implementation details and behavior of this evaluator. Looking at the scoring system section, I see it uses a 5-level categorical scale (0.0, 0.25, 0.5, 0.75, 1.0) and mentions that 'A response passes the evaluation if the score is >= 0.5'. This is a concrete threshold that would be important for engineers implementing tests. A good question would ask about this passing threshold, as it's a specific implementation detail that affects how the evaluator is used in practice.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:44:20.739759Z",
     "start_time": "2025-12-29T17:44:20.737401Z"
    }
   },
   "cell_type": "code",
   "source": "question.question",
   "id": "f12343201786779d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the minimum score threshold required for a response to pass the FaithfulnessEvaluator, and what does this score represent on the categorical scale?'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:51:19.126349Z",
     "start_time": "2025-12-29T16:51:19.122042Z"
    }
   },
   "cell_type": "code",
   "source": "strands = get_all_files_in_dir('../working_dir/docs/strandsagents.com')",
   "id": "d206f9b33b290aac",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:02:30.775064Z",
     "start_time": "2025-12-29T16:53:12.349346Z"
    }
   },
   "cell_type": "code",
   "source": "strands_sample = choose_random_files(strands)",
   "id": "ac0954590930f823",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file to sample. Num Files : 1\n",
      "Added file to sample. Num Files : 2\n",
      "Added file to sample. Num Files : 3\n",
      "Added file to sample. Num Files : 4\n",
      "Added file to sample. Num Files : 5\n",
      "Added file to sample. Num Files : 6\n",
      "Added file to sample. Num Files : 7\n",
      "Added file to sample. Num Files : 8\n",
      "Added file to sample. Num Files : 9\n",
      "Added file to sample. Num Files : 10\n",
      "Added file to sample. Num Files : 11\n",
      "Added file to sample. Num Files : 12\n",
      "Added file to sample. Num Files : 13\n",
      "Added file to sample. Num Files : 14\n",
      "Added file to sample. Num Files : 15\n",
      "Added file to sample. Num Files : 16\n",
      "Added file to sample. Num Files : 17\n",
      "Added file to sample. Num Files : 18\n",
      "Added file to sample. Num Files : 19\n",
      "Added file to sample. Num Files : 20\n",
      "Added file to sample. Num Files : 21\n",
      "Added file to sample. Num Files : 22\n",
      "Added file to sample. Num Files : 23\n",
      "Added file to sample. Num Files : 24\n",
      "Added file to sample. Num Files : 25\n",
      "Added file to sample. Num Files : 26\n",
      "Added file to sample. Num Files : 27\n",
      "Added file to sample. Num Files : 28\n",
      "Added file to sample. Num Files : 29\n",
      "Added file to sample. Num Files : 30\n",
      "Added file to sample. Num Files : 31\n",
      "Added file to sample. Num Files : 31\n",
      "Added file to sample. Num Files : 32\n",
      "Added file to sample. Num Files : 33\n",
      "Added file to sample. Num Files : 34\n",
      "Added file to sample. Num Files : 34\n",
      "Added file to sample. Num Files : 35\n",
      "Added file to sample. Num Files : 36\n",
      "Added file to sample. Num Files : 36\n",
      "Added file to sample. Num Files : 37\n",
      "Added file to sample. Num Files : 38\n",
      "Added file to sample. Num Files : 39\n",
      "Added file to sample. Num Files : 40\n",
      "Added file to sample. Num Files : 41\n",
      "Added file to sample. Num Files : 41\n",
      "Added file to sample. Num Files : 41\n",
      "Added file to sample. Num Files : 42\n",
      "Added file to sample. Num Files : 43\n",
      "Added file to sample. Num Files : 43\n",
      "Added file to sample. Num Files : 44\n",
      "Added file to sample. Num Files : 45\n",
      "Added file to sample. Num Files : 46\n",
      "Added file to sample. Num Files : 47\n",
      "Added file to sample. Num Files : 48\n",
      "Added file to sample. Num Files : 48\n",
      "Added file to sample. Num Files : 49\n",
      "Added file to sample. Num Files : 49\n",
      "Added file to sample. Num Files : 50\n",
      "Added file to sample. Num Files : 51\n",
      "Added file to sample. Num Files : 52\n",
      "Added file to sample. Num Files : 52\n",
      "Added file to sample. Num Files : 53\n",
      "Added file to sample. Num Files : 54\n",
      "Added file to sample. Num Files : 55\n",
      "Added file to sample. Num Files : 56\n",
      "Added file to sample. Num Files : 56\n",
      "Added file to sample. Num Files : 57\n",
      "Added file to sample. Num Files : 58\n",
      "Added file to sample. Num Files : 59\n",
      "Added file to sample. Num Files : 60\n",
      "Added file to sample. Num Files : 60\n",
      "Added file to sample. Num Files : 61\n",
      "Added file to sample. Num Files : 62\n",
      "Added file to sample. Num Files : 63\n",
      "Added file to sample. Num Files : 64\n",
      "Added file to sample. Num Files : 65\n",
      "Added file to sample. Num Files : 65\n",
      "Added file to sample. Num Files : 65\n",
      "Added file to sample. Num Files : 66\n",
      "Added file to sample. Num Files : 67\n",
      "Added file to sample. Num Files : 68\n",
      "Added file to sample. Num Files : 69\n",
      "Added file to sample. Num Files : 70\n",
      "Added file to sample. Num Files : 70\n",
      "Added file to sample. Num Files : 71\n",
      "Added file to sample. Num Files : 72\n",
      "Added file to sample. Num Files : 72\n",
      "Added file to sample. Num Files : 73\n",
      "Added file to sample. Num Files : 74\n",
      "Added file to sample. Num Files : 75\n",
      "Added file to sample. Num Files : 76\n",
      "Added file to sample. Num Files : 77\n",
      "Added file to sample. Num Files : 78\n",
      "Added file to sample. Num Files : 79\n",
      "Added file to sample. Num Files : 80\n",
      "Added file to sample. Num Files : 81\n",
      "Added file to sample. Num Files : 82\n",
      "Added file to sample. Num Files : 83\n",
      "Added file to sample. Num Files : 84\n",
      "Added file to sample. Num Files : 85\n",
      "Added file to sample. Num Files : 85\n",
      "Added file to sample. Num Files : 85\n",
      "Added file to sample. Num Files : 85\n",
      "Added file to sample. Num Files : 86\n",
      "Added file to sample. Num Files : 87\n",
      "Added file to sample. Num Files : 88\n",
      "Added file to sample. Num Files : 89\n",
      "Added file to sample. Num Files : 90\n",
      "Added file to sample. Num Files : 90\n",
      "Added file to sample. Num Files : 90\n",
      "Added file to sample. Num Files : 90\n",
      "Added file to sample. Num Files : 91\n",
      "Added file to sample. Num Files : 92\n",
      "Added file to sample. Num Files : 92\n",
      "Added file to sample. Num Files : 92\n",
      "Added file to sample. Num Files : 93\n",
      "Added file to sample. Num Files : 94\n",
      "Added file to sample. Num Files : 95\n",
      "Added file to sample. Num Files : 96\n",
      "Added file to sample. Num Files : 96\n",
      "Added file to sample. Num Files : 96\n",
      "Added file to sample. Num Files : 97\n",
      "Added file to sample. Num Files : 98\n",
      "Added file to sample. Num Files : 99\n",
      "Added file to sample. Num Files : 99\n",
      "Added file to sample. Num Files : 99\n",
      "Added file to sample. Num Files : 99\n",
      "Added file to sample. Num Files : 99\n",
      "Added file to sample. Num Files : 100\n",
      "Added file to sample. Num Files : 100\n",
      "Added file to sample. Num Files : 101\n",
      "Added file to sample. Num Files : 102\n",
      "Added file to sample. Num Files : 102\n",
      "Added file to sample. Num Files : 103\n",
      "Added file to sample. Num Files : 104\n",
      "Added file to sample. Num Files : 105\n",
      "Added file to sample. Num Files : 106\n",
      "Added file to sample. Num Files : 107\n",
      "Added file to sample. Num Files : 107\n",
      "Added file to sample. Num Files : 107\n",
      "Added file to sample. Num Files : 108\n",
      "Added file to sample. Num Files : 108\n",
      "Added file to sample. Num Files : 108\n",
      "Added file to sample. Num Files : 108\n",
      "Added file to sample. Num Files : 109\n",
      "Added file to sample. Num Files : 110\n",
      "Added file to sample. Num Files : 110\n",
      "Added file to sample. Num Files : 111\n",
      "Added file to sample. Num Files : 112\n",
      "Added file to sample. Num Files : 112\n",
      "Added file to sample. Num Files : 113\n",
      "Added file to sample. Num Files : 113\n",
      "Added file to sample. Num Files : 113\n",
      "Added file to sample. Num Files : 114\n",
      "Added file to sample. Num Files : 114\n",
      "Added file to sample. Num Files : 114\n",
      "Added file to sample. Num Files : 115\n",
      "Added file to sample. Num Files : 115\n",
      "Added file to sample. Num Files : 115\n",
      "Added file to sample. Num Files : 116\n",
      "Added file to sample. Num Files : 117\n",
      "Added file to sample. Num Files : 117\n",
      "Added file to sample. Num Files : 118\n",
      "Added file to sample. Num Files : 118\n",
      "Added file to sample. Num Files : 119\n",
      "Added file to sample. Num Files : 119\n",
      "Added file to sample. Num Files : 119\n",
      "Added file to sample. Num Files : 120\n",
      "Added file to sample. Num Files : 120\n",
      "Added file to sample. Num Files : 120\n",
      "Added file to sample. Num Files : 120\n",
      "Added file to sample. Num Files : 120\n",
      "Added file to sample. Num Files : 120\n",
      "Added file to sample. Num Files : 121\n",
      "Added file to sample. Num Files : 122\n",
      "Added file to sample. Num Files : 122\n",
      "Added file to sample. Num Files : 123\n",
      "Added file to sample. Num Files : 123\n",
      "Added file to sample. Num Files : 123\n",
      "Added file to sample. Num Files : 124\n",
      "Added file to sample. Num Files : 125\n",
      "Added file to sample. Num Files : 126\n",
      "Added file to sample. Num Files : 127\n",
      "Added file to sample. Num Files : 127\n",
      "Added file to sample. Num Files : 128\n",
      "Added file to sample. Num Files : 128\n",
      "Added file to sample. Num Files : 128\n",
      "Added file to sample. Num Files : 129\n",
      "Added file to sample. Num Files : 130\n",
      "Added file to sample. Num Files : 131\n",
      "Added file to sample. Num Files : 132\n",
      "Added file to sample. Num Files : 132\n",
      "Added file to sample. Num Files : 133\n",
      "Added file to sample. Num Files : 134\n",
      "Added file to sample. Num Files : 134\n",
      "Added file to sample. Num Files : 134\n",
      "Added file to sample. Num Files : 134\n",
      "Added file to sample. Num Files : 135\n",
      "Added file to sample. Num Files : 135\n",
      "Added file to sample. Num Files : 136\n",
      "Added file to sample. Num Files : 137\n",
      "Added file to sample. Num Files : 138\n",
      "Added file to sample. Num Files : 139\n",
      "Added file to sample. Num Files : 140\n",
      "Added file to sample. Num Files : 141\n",
      "Added file to sample. Num Files : 141\n",
      "Added file to sample. Num Files : 142\n",
      "Added file to sample. Num Files : 142\n",
      "Added file to sample. Num Files : 143\n",
      "Added file to sample. Num Files : 144\n",
      "Added file to sample. Num Files : 145\n",
      "Added file to sample. Num Files : 146\n",
      "Added file to sample. Num Files : 147\n",
      "Added file to sample. Num Files : 147\n",
      "Added file to sample. Num Files : 148\n",
      "Added file to sample. Num Files : 148\n",
      "Added file to sample. Num Files : 148\n",
      "Added file to sample. Num Files : 148\n",
      "Added file to sample. Num Files : 149\n",
      "Added file to sample. Num Files : 149\n",
      "Added file to sample. Num Files : 149\n",
      "Added file to sample. Num Files : 149\n",
      "Added file to sample. Num Files : 150\n",
      "Added file to sample. Num Files : 150\n",
      "Added file to sample. Num Files : 151\n",
      "Added file to sample. Num Files : 151\n",
      "Added file to sample. Num Files : 152\n",
      "Added file to sample. Num Files : 153\n",
      "Added file to sample. Num Files : 153\n",
      "Added file to sample. Num Files : 153\n",
      "Added file to sample. Num Files : 153\n",
      "Added file to sample. Num Files : 154\n",
      "Added file to sample. Num Files : 154\n",
      "Added file to sample. Num Files : 155\n",
      "Added file to sample. Num Files : 155\n",
      "Added file to sample. Num Files : 155\n",
      "Added file to sample. Num Files : 155\n",
      "Added file to sample. Num Files : 155\n",
      "Added file to sample. Num Files : 155\n",
      "Added file to sample. Num Files : 156\n",
      "Added file to sample. Num Files : 157\n",
      "Added file to sample. Num Files : 157\n",
      "Added file to sample. Num Files : 158\n",
      "Added file to sample. Num Files : 159\n",
      "Added file to sample. Num Files : 159\n",
      "Added file to sample. Num Files : 160\n",
      "Added file to sample. Num Files : 160\n",
      "Added file to sample. Num Files : 160\n",
      "Added file to sample. Num Files : 160\n",
      "Added file to sample. Num Files : 160\n",
      "Added file to sample. Num Files : 160\n",
      "Added file to sample. Num Files : 161\n",
      "Added file to sample. Num Files : 161\n",
      "Added file to sample. Num Files : 161\n",
      "Added file to sample. Num Files : 161\n",
      "Added file to sample. Num Files : 162\n",
      "Added file to sample. Num Files : 162\n",
      "Added file to sample. Num Files : 162\n",
      "Added file to sample. Num Files : 163\n",
      "Added file to sample. Num Files : 163\n",
      "Added file to sample. Num Files : 163\n",
      "Added file to sample. Num Files : 163\n",
      "Added file to sample. Num Files : 164\n",
      "Added file to sample. Num Files : 165\n",
      "Added file to sample. Num Files : 166\n",
      "Added file to sample. Num Files : 167\n",
      "Added file to sample. Num Files : 168\n",
      "Added file to sample. Num Files : 168\n",
      "Added file to sample. Num Files : 168\n",
      "Added file to sample. Num Files : 168\n",
      "Added file to sample. Num Files : 169\n",
      "Added file to sample. Num Files : 170\n",
      "Added file to sample. Num Files : 170\n",
      "Added file to sample. Num Files : 170\n",
      "Added file to sample. Num Files : 171\n",
      "Added file to sample. Num Files : 172\n",
      "Added file to sample. Num Files : 172\n",
      "Added file to sample. Num Files : 172\n",
      "Added file to sample. Num Files : 172\n",
      "Added file to sample. Num Files : 173\n",
      "Added file to sample. Num Files : 173\n",
      "Added file to sample. Num Files : 173\n",
      "Added file to sample. Num Files : 174\n",
      "Added file to sample. Num Files : 175\n",
      "Added file to sample. Num Files : 175\n",
      "Added file to sample. Num Files : 175\n",
      "Added file to sample. Num Files : 176\n",
      "Added file to sample. Num Files : 176\n",
      "Added file to sample. Num Files : 176\n",
      "Added file to sample. Num Files : 176\n",
      "Added file to sample. Num Files : 177\n",
      "Added file to sample. Num Files : 178\n",
      "Added file to sample. Num Files : 178\n",
      "Added file to sample. Num Files : 179\n",
      "Added file to sample. Num Files : 179\n",
      "Added file to sample. Num Files : 180\n",
      "Added file to sample. Num Files : 180\n",
      "Added file to sample. Num Files : 180\n",
      "Added file to sample. Num Files : 180\n",
      "Added file to sample. Num Files : 180\n",
      "Added file to sample. Num Files : 180\n",
      "Added file to sample. Num Files : 181\n",
      "Added file to sample. Num Files : 181\n",
      "Added file to sample. Num Files : 181\n",
      "Added file to sample. Num Files : 182\n",
      "Added file to sample. Num Files : 182\n",
      "Added file to sample. Num Files : 183\n",
      "Added file to sample. Num Files : 183\n",
      "Added file to sample. Num Files : 183\n",
      "Added file to sample. Num Files : 183\n",
      "Added file to sample. Num Files : 183\n",
      "Added file to sample. Num Files : 184\n",
      "Added file to sample. Num Files : 184\n",
      "Added file to sample. Num Files : 185\n",
      "Added file to sample. Num Files : 186\n",
      "Added file to sample. Num Files : 186\n",
      "Added file to sample. Num Files : 186\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 187\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 188\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 189\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 190\n",
      "Added file to sample. Num Files : 191\n",
      "Added file to sample. Num Files : 192\n",
      "Added file to sample. Num Files : 192\n",
      "Added file to sample. Num Files : 193\n",
      "Added file to sample. Num Files : 194\n",
      "Added file to sample. Num Files : 195\n",
      "Added file to sample. Num Files : 196\n",
      "Added file to sample. Num Files : 196\n",
      "Added file to sample. Num Files : 196\n",
      "Added file to sample. Num Files : 196\n",
      "Added file to sample. Num Files : 196\n",
      "Added file to sample. Num Files : 196\n",
      "Added file to sample. Num Files : 197\n",
      "Added file to sample. Num Files : 197\n",
      "Added file to sample. Num Files : 197\n",
      "Added file to sample. Num Files : 197\n",
      "Added file to sample. Num Files : 197\n",
      "Added file to sample. Num Files : 198\n",
      "Added file to sample. Num Files : 198\n",
      "Added file to sample. Num Files : 199\n",
      "Added file to sample. Num Files : 199\n",
      "Added file to sample. Num Files : 200\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:14:03.752358Z",
     "start_time": "2025-12-29T17:14:03.748600Z"
    }
   },
   "cell_type": "code",
   "source": "strands_sample[0]",
   "id": "2b29c4e443447562",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../working_dir/docs/strandsagents.com/latest_documentation_docs_user-guide_evals-sdk_evaluators_faithfulness_evaluator.md')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:14:38.368344Z",
     "start_time": "2025-12-29T17:14:38.365819Z"
    }
   },
   "cell_type": "code",
   "source": "strans_file_paths = [str(x) for x in strands_sample]",
   "id": "2e768bcbd01f0033",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:19:12.026236Z",
     "start_time": "2025-12-29T17:19:12.021799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../working_dir/eval/sample.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(str, f, ensure_ascii=False)"
   ],
   "id": "2a03371a02082f95",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b20264d6ca74b0a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58f340281c9e01d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:24:25.291420Z",
     "start_time": "2025-12-29T16:24:25.286380Z"
    }
   },
   "cell_type": "code",
   "source": "md_file = read_file(strands_sample[0])",
   "id": "a50e376d93722cd1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:53:08.210944Z",
     "start_time": "2025-12-29T16:53:07.655289Z"
    }
   },
   "cell_type": "code",
   "source": "get_num_tokens(md_file)",
   "id": "9fd9dbd967fb7c72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4078"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:24:31.662712Z",
     "start_time": "2025-12-29T16:24:31.660216Z"
    }
   },
   "cell_type": "code",
   "source": "md_file",
   "id": "4d971abf8eed3e94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\nurl: https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator\\ndepth: 1\\n---\\n\\n[ Skip to content ](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#trajectory-evaluator)\\n# Trajectory Evaluator[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#trajectory-evaluator \"Permanent link\")\\n## Overview[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#overview \"Permanent link\")\\nThe `TrajectoryEvaluator` is an LLM-based evaluator that assesses the sequence of actions or tool calls made by an agent during task execution. It evaluates whether the agent followed an appropriate path to reach its goal, making it ideal for evaluating multi-step reasoning and tool usage patterns. A complete example can be found [here](https://github.com/strands-agents/docs/blob/main/docs/examples/evals-sdk/trajectory_evaluator.py).\\n## Key Features[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#key-features \"Permanent link\")\\n  * **Action Sequence Evaluation** : Assesses the order and appropriateness of actions taken\\n  * **Tool Usage Analysis** : Evaluates whether correct tools were selected and used\\n  * **Built-in Scoring Tools** : Includes helper tools for exact, in-order, and any-order matching\\n  * **Flexible Rubric System** : Define custom criteria for trajectory evaluation\\n  * **LLM-as-a-Judge** : Uses a language model to perform nuanced trajectory assessments\\n  * **Async Support** : Supports both synchronous and asynchronous evaluation\\n\\n\\n## When to Use[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#when-to-use \"Permanent link\")\\nUse the `TrajectoryEvaluator` when you need to:\\n  * Evaluate the sequence of tool calls or actions taken by an agent\\n  * Verify that agents follow expected workflows or procedures\\n  * Assess whether agents use tools in the correct order\\n  * Compare different agent strategies for solving the same problem\\n  * Ensure agents don\\'t skip critical steps in multi-step processes\\n  * Evaluate reasoning chains and decision-making patterns\\n\\n\\n## Parameters[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#parameters \"Permanent link\")\\n###  `rubric` (required)[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#rubric-required \"Permanent link\")\\n  * **Type** : `str`\\n  * **Description** : The evaluation criteria for assessing trajectories. Should specify what constitutes a good action sequence.\\n\\n\\n###  `trajectory_description` (optional)[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#trajectory_description-optional \"Permanent link\")\\n  * **Type** : `dict | None`\\n  * **Default** : `None`\\n  * **Description** : A dictionary describing available trajectory types (e.g., tool descriptions). Can be updated dynamically using `update_trajectory_description()`.\\n\\n\\n###  `model` (optional)[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#model-optional \"Permanent link\")\\n  * **Type** : `Union[Model, str, None]`\\n  * **Default** : `None` (uses default Bedrock model)\\n  * **Description** : The model to use as the judge. Can be a model ID string or a Model instance.\\n\\n\\n###  `system_prompt` (optional)[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#system_prompt-optional \"Permanent link\")\\n  * **Type** : `str`\\n  * **Default** : Built-in template\\n  * **Description** : Custom system prompt to guide the judge model\\'s behavior.\\n\\n\\n###  `include_inputs` (optional)[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#include_inputs-optional \"Permanent link\")\\n  * **Type** : `bool`\\n  * **Default** : `True`\\n  * **Description** : Whether to include the input prompt in the evaluation context.\\n\\n\\n## Built-in Scoring Tools[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#built-in-scoring-tools \"Permanent link\")\\nThe `TrajectoryEvaluator` comes with three helper tools that the judge can use:\\n  1. **`exact_match_scorer`**: Checks if actual trajectory exactly matches expected trajectory\\n  2. **`in_order_match_scorer`**: Checks if expected actions appear in order (allows extra actions)\\n  3. **`any_order_match_scorer`**: Checks if all expected actions are present (order doesn\\'t matter)\\n\\n\\nThese tools help the judge make consistent scoring decisions based on trajectory matching.\\n## Using Extractors to Prevent Overflow[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#using-extractors-to-prevent-overflow \"Permanent link\")\\nWhen working with trajectories, it\\'s important to use extractors to efficiently extract tool usage information without overwhelming the evaluation context. The `tools_use_extractor` module provides utility functions for this purpose.\\n### Available Extractor Functions[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#available-extractor-functions \"Permanent link\")\\n####  `extract_agent_tools_used_from_messages(agent_messages)`[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#extract_agent_tools_used_from_messagesagent_messages \"Permanent link\")\\nExtracts tool usage information from agent message history. Returns a list of tools used with their names, inputs, and results.\\n```\\nfrom strands_evals.extractors import tools_use_extractor\\n\\n# Extract tools from agent messages\\ntrajectory = tools_use_extractor.extract_agent_tools_used_from_messages(\\n    agent.messages\\n)\\n# Returns: [{\"name\": \"tool_name\", \"input\": {...}, \"tool_result\": \"...\"}, ...]\\n\\n```\\n\\n####  `extract_agent_tools_used_from_metrics(agent_result)`[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#extract_agent_tools_used_from_metricsagent_result \"Permanent link\")\\nExtracts tool usage metrics from agent execution result, including call counts and timing information.\\n```\\n# Extract tools from agent metrics\\ntools_metrics = tools_use_extractor.extract_agent_tools_used_from_metrics(\\n    agent_result\\n)\\n# Returns: [{\"name\": \"tool_name\", \"call_count\": 3, \"success_count\": 3, ...}, ...]\\n\\n```\\n\\n####  `extract_tools_description(agent, is_short=True)`[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#extract_tools_descriptionagent-is_shorttrue \"Permanent link\")\\nExtracts tool descriptions from the agent\\'s tool registry. Use this to update the trajectory description dynamically.\\n```\\n# Extract tool descriptions\\ntool_descriptions = tools_use_extractor.extract_tools_description(\\n    agent, \\n    is_short=True  # Returns only descriptions, not full config\\n)\\n# Returns: {\"tool_name\": \"tool description\", ...}\\n\\n# Update evaluator with tool descriptions\\nevaluator.update_trajectory_description(tool_descriptions)\\n\\n```\\n\\n## Basic Usage[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#basic-usage \"Permanent link\")\\n```\\nfrom strands import Agent, tool\\nfrom strands_evals import Case, Experiment\\nfrom strands_evals.evaluators import TrajectoryEvaluator\\nfrom strands_evals.extractors import tools_use_extractor\\nfrom strands_evals.types import TaskOutput\\n\\n# Define tools\\n@tool\\ndef search_database(query: str) -> str:\\n    \"\"\"Search the database for information.\"\"\"\\n    return f\"Results for: {query}\"\\n\\n@tool\\ndef format_results(data: str) -> str:\\n    \"\"\"Format search results for display.\"\"\"\\n    return f\"Formatted: {data}\"\\n\\n# Define task function\\ndef get_response(case: Case) -> dict:\\n    agent = Agent(\\n        tools=[search_database, format_results],\\n        system_prompt=\"Search and format results.\",\\n        callback_handler=None\\n    )\\n    response = agent(case.input)\\n\\n    # Use extractor to get trajectory efficiently\\n    trajectory = tools_use_extractor.extract_agent_tools_used_from_messages(\\n        agent.messages\\n    )\\n\\n    # Update evaluator with tool descriptions to prevent overflow\\n    evaluator.update_trajectory_description(\\n        tools_use_extractor.extract_tools_description(agent)\\n    )\\n\\n    return TaskOutput(\\n        output=str(response),\\n        trajectory=trajectory\\n    )\\n\\n# Create test cases with expected trajectories\\ntest_cases = [\\n    Case[str, str](\\n        name=\"search-and-format\",\\n        input=\"Find information about Python\",\\n        expected_trajectory=[\"search_database\", \"format_results\"],\\n        metadata={\"category\": \"search\"}\\n    ),\\n]\\n\\n# Create evaluator\\nevaluator = TrajectoryEvaluator(\\n    rubric=\"\"\"\\n    The trajectory should follow the correct sequence:\\n    1. Search the database first\\n    2. Format the results second\\n\\n    Score 1.0 if the sequence is correct.\\n    Score 0.5 if tools are used but in wrong order.\\n    Score 0.0 if wrong tools are used or steps are missing.\\n    \"\"\",\\n    include_inputs=True\\n)\\n\\n# Run evaluation\\nexperiment = Experiment[str, str](cases=test_cases, evaluators=[evaluator])\\nreports = experiment.run_evaluations(get_response)\\nreports[0].run_display()\\n\\n```\\n\\n## Preventing Context Overflow[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#preventing-context-overflow \"Permanent link\")\\nWhen evaluating trajectories with many tool calls or complex tool configurations, use extractors to keep the evaluation context manageable:\\n```\\ndef task_with_many_tools(case: Case) -> dict:\\n    agent = Agent(\\n        tools=[tool1, tool2, tool3, tool4, tool5],  # Many tools\\n        callback_handler=None\\n    )\\n    response = agent(case.input)\\n\\n    # Extract short descriptions only (prevents overflow)\\n    tool_descriptions = tools_use_extractor.extract_tools_description(\\n        agent, \\n        is_short=True  # Only descriptions, not full config\\n    )\\n    evaluator.update_trajectory_description(tool_descriptions)\\n\\n    return TaskOutput(output=str(response), trajectory=trajectory=tools_use_extractor.extract_agent_tools_used_from_messages(agent.messages))\\n\\n```\\n\\n## Evaluation Output[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#evaluation-output \"Permanent link\")\\nThe `TrajectoryEvaluator` returns `EvaluationOutput` objects with:\\n  * **score** : Float between 0.0 and 1.0 representing trajectory quality\\n  * **test_pass** : Boolean indicating if the trajectory passed evaluation\\n  * **reason** : String containing the judge\\'s reasoning\\n  * **label** : Optional label categorizing the result\\n\\n\\n## Best Practices[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#best-practices \"Permanent link\")\\n  1. **Use Extractors** : Always use `tools_use_extractor` functions to efficiently extract trajectory information\\n  2. **Update Descriptions Dynamically** : Call `update_trajectory_description()` with extracted tool descriptions\\n  3. **Keep Trajectories Concise** : Extract only necessary information (e.g., tool names) to prevent context overflow\\n  4. **Define Clear Expected Trajectories** : Specify exact sequences of expected actions\\n  5. **Choose Appropriate Matching** : Select between exact, in-order, or any-order matching based on your needs\\n\\n\\n## Common Patterns[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#common-patterns \"Permanent link\")\\n### Pattern 1: Workflow Validation[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#pattern-1-workflow-validation \"Permanent link\")\\n```\\nevaluator = TrajectoryEvaluator(\\n    rubric=\"\"\"\\n    Required workflow:\\n    1. Authenticate user\\n    2. Validate input\\n    3. Process request\\n    4. Log action\\n\\n    Score 1.0 if all steps present in order.\\n    Score 0.0 if any step is missing.\\n    \"\"\"\\n)\\n\\n```\\n\\n### Pattern 2: Efficiency Evaluation[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#pattern-2-efficiency-evaluation \"Permanent link\")\\n```\\nevaluator = TrajectoryEvaluator(\\n    rubric=\"\"\"\\n    Evaluate efficiency:\\n    - Minimum necessary steps: Score 1.0\\n    - Some redundant steps: Score 0.7\\n    - Many redundant steps: Score 0.4\\n    - Inefficient approach: Score 0.0\\n    \"\"\"\\n)\\n\\n```\\n\\n### Pattern 3: Using Metrics for Analysis[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#pattern-3-using-metrics-for-analysis \"Permanent link\")\\n```\\ndef task_with_metrics(case: Case) -> dict:\\n    agent = Agent(tools=[...], callback_handler=None)\\n    response = agent(case.input)\\n\\n    # Get both trajectory and metrics\\n    trajectory = tools_use_extractor.extract_agent_tools_used_from_messages(agent.messages)\\n    metrics = tools_use_extractor.extract_agent_tools_used_from_metrics(response)\\n\\n    # Use metrics for additional analysis\\n    print(f\"Total tool calls: {sum(m[\\'call_count\\'] for m in metrics)}\")\\n\\n    return TaskOutput(output=str(response), trajectory=trajectory)\\n\\n```\\n\\n## Related Evaluators[¶](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/trajectory_evaluator/#related-evaluators \"Permanent link\")\\n  * [**OutputEvaluator**](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/output_evaluator/): Evaluates the quality of final outputs\\n  * [**ToolParameterAccuracyEvaluator**](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/tool_parameter_evaluator/): Evaluates if tool parameters are correct\\n  * [**ToolSelectionAccuracyEvaluator**](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/tool_selection_evaluator/): Evaluates if correct tools were selected\\n  * [**GoalSuccessRateEvaluator**](https://strandsagents.com/latest/documentation/docs/user-guide/evals-sdk/evaluators/goal_success_rate_evaluator/): Evaluates if overall goals were achieved\\n\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:13:02.116535Z",
     "start_time": "2025-12-29T16:13:02.114859Z"
    }
   },
   "cell_type": "code",
   "source": "p = Path('../working_dir/strandsagents.com')",
   "id": "522e199f8db8858d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:13:21.086111Z",
     "start_time": "2025-12-29T16:13:21.083624Z"
    }
   },
   "cell_type": "code",
   "source": "list(p.glob('*.md'))",
   "id": "6cf898993df5b21d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:13:45.123217Z",
     "start_time": "2025-12-29T16:13:45.120181Z"
    }
   },
   "cell_type": "code",
   "source": "len(strands)",
   "id": "6be3846469673049",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:17:14.802499Z",
     "start_time": "2025-12-29T16:17:14.799014Z"
    }
   },
   "cell_type": "code",
   "source": "sample = choose_random_files(strands)",
   "id": "9755c544113bebb1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:17:18.294818Z",
     "start_time": "2025-12-29T16:17:18.292378Z"
    }
   },
   "cell_type": "code",
   "source": "len(sample)",
   "id": "4b125800e56aaa75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:17:21.000623Z",
     "start_time": "2025-12-29T16:17:20.998080Z"
    }
   },
   "cell_type": "code",
   "source": "sample[0]",
   "id": "6d27036bd1c70b80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../working_dir/docs/strandsagents.com/latest_documentation_docs_user-guide_concepts_model-providers_llamacpp.md')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a63d5580f3d3952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bf59da40b89984f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
